{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "import joblib\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620264362298
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "\r\n",
        "import gzip\r\n",
        "import numpy as np\r\n",
        "import struct\r\n",
        "\r\n",
        "\r\n",
        "# load compressed MNIST gz files and return numpy arrays\r\n",
        "def load_data(filename, label=False):\r\n",
        "    with gzip.open(filename) as gz:\r\n",
        "        struct.unpack('I', gz.read(4))\r\n",
        "        n_items = struct.unpack('>I', gz.read(4))\r\n",
        "        if not label:\r\n",
        "            n_rows = struct.unpack('>I', gz.read(4))[0]\r\n",
        "            n_cols = struct.unpack('>I', gz.read(4))[0]\r\n",
        "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\r\n",
        "            res = res.reshape(n_items[0], n_rows * n_cols)\r\n",
        "        else:\r\n",
        "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\r\n",
        "            res = res.reshape(n_items[0], 1)\r\n",
        "    return res\r\n",
        "\r\n",
        "\r\n",
        "# one-hot encode a 1-D array\r\n",
        "def one_hot_encode(array, num_of_classes):\r\n",
        "    return np.eye(num_of_classes)[array.reshape(-1)]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620263987442
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore data\r\n",
        "\r\n",
        "Before you train a model, you need to understand the data that you are using to train it. In this section you learn how to:\r\n",
        "\r\n",
        "* Download the MNIST dataset\r\n",
        "* Display some sample images\r\n",
        "\r\n",
        "### Download the MNIST dataset\r\n",
        "\r\n",
        "Use Azure Open Datasets to get the raw MNIST data files. [Azure Open Datasets](https://docs.microsoft.com/azure/open-datasets/overview-what-are-open-datasets) are curated public datasets that you can use to add scenario-specific features to machine learning solutions for more accurate models. Each dataset has a corrseponding class, `MNIST` in this case, to retrieve the data in different ways.\r\n",
        "\r\n",
        "This code retrieves the data as a `FileDataset` object, which is a subclass of `Dataset`. A `FileDataset` references single or multiple files of any format in your datastores or public urls. The class provides you with the ability to download or mount the files to your compute by creating a reference to the data source location. Additionally, you register the Dataset to your workspace for easy retrieval during training.\r\n",
        "\r\n",
        "Follow the [how-to](https://aka.ms/azureml/howto/createdatasets) to learn more about Datasets and their usage in the SDK."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.opendatasets import MNIST\r\n",
        "\r\n",
        "data_folder = os.path.join(os.getcwd(), 'data')\r\n",
        "os.makedirs(data_folder, exist_ok=True)\r\n",
        "\r\n",
        "mnist_file_dataset = MNIST.get_file_dataset()\r\n",
        "mnist_file_dataset.download(data_folder, overwrite=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620263994894
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display some sample images\r\n",
        "\r\n",
        "Load the compressed files into `numpy` arrays. Then use `matplotlib` to plot 30 random images from the dataset with their labels above them. Note this step requires a `load_data` function that's included in an `utils.py` file. This file is included in the sample folder. Please make sure it is placed in the same folder as this notebook. The `load_data` function simply parses the compresse files into numpy arrays."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure utils.py is in the same directory as this code\r\n",
        "# from utils import load_data\r\n",
        "import glob\r\n",
        "\r\n",
        "# note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the model converge faster.\r\n",
        "X_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\r\n",
        "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\r\n",
        "y_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\r\n",
        "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620263996157
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Model\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set regularization rate\r\n",
        "reg = 0.5\r\n",
        "\r\n",
        "print('Train a logistic regression model with regularization rate of', reg)\r\n",
        "clf = LogisticRegression(C=1.0/reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\r\n",
        "clf.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train a logistic regression model with regularization rate of 0.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620264108178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the test set\r\n",
        "y_hat = clf.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620264172475
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy on the prediction\r\n",
        "acc = np.average(y_hat == y_test)\r\n",
        "print('Accuracy is', acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.9193\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620264173582
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Run\r\n",
        "\r\n",
        "# get hold of the current run\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "run.log('regularization rate', np.float(reg))\r\n",
        "run.log('accuracy', np.float(acc))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('outputs', exist_ok=True)\r\n",
        "\r\n",
        "# note file saved in the outputs folder is automatically uploaded into experiment record\r\n",
        "joblib.dump(value=clf, filename='outputs/sklearn_mnist_model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}