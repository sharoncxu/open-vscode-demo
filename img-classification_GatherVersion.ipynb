{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathered Notebook\n",
        "\n",
        " This notebook was generated by an experimental feature called \"Gather\". The intent is that it contains only the code and cells required to produce the same results as the cell originally selected for gathering. Please note that the Python analysis is quite conservative, so if it is unsure whether a line of code is necessary for execution, it will err on the side of including it.\n",
        "\n",
        "**Please let us know if you are satisfied with what was gathered by [taking this survey](https://aka.ms/gathersurvey).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gzip\n",
        "import struct\n",
        "def load_data(filename, label=False):\n",
        "    with gzip.open(filename) as gz:\n",
        "        struct.unpack('I', gz.read(4))\n",
        "        n_items = struct.unpack('>I', gz.read(4))\n",
        "        if not label:\n",
        "            n_rows = struct.unpack('>I', gz.read(4))[0]\n",
        "            n_cols = struct.unpack('>I', gz.read(4))[0]\n",
        "            res = np.frombuffer(gz.read(n_items[0] * n_rows * n_cols), dtype=np.uint8)\n",
        "            res = res.reshape(n_items[0], n_rows * n_cols)\n",
        "        else:\n",
        "            res = np.frombuffer(gz.read(n_items[0]), dtype=np.uint8)\n",
        "            res = res.reshape(n_items[0], 1)\n",
        "    return res\n",
        "\n",
        "\n",
        "# one-hot encode a 1-D array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/sharonxu-ci5/code/Users/sharonxu/mlads/data/https%3A/%2Fazureopendatastorage.azurefd.net/mnist/t10k-images-idx3-ubyte.gz',\n",
              " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sharonxu-ci5/code/Users/sharonxu/mlads/data/https%3A/%2Fazureopendatastorage.azurefd.net/mnist/t10k-labels-idx1-ubyte.gz',\n",
              " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sharonxu-ci5/code/Users/sharonxu/mlads/data/https%3A/%2Fazureopendatastorage.azurefd.net/mnist/train-images-idx3-ubyte.gz',\n",
              " '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sharonxu-ci5/code/Users/sharonxu/mlads/data/https%3A/%2Fazureopendatastorage.azurefd.net/mnist/train-labels-idx1-ubyte.gz']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from azureml.opendatasets import MNIST\n",
        "data_folder = os.path.join(os.getcwd(), 'data')\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "mnist_file_dataset = MNIST.get_file_dataset()\n",
        "mnist_file_dataset.download(data_folder, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "X_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
        "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
        "y_train = load_data(glob.glob(os.path.join(data_folder,\"**/train-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
        "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reg = 0.5\n",
        "clf = LogisticRegression(C=1.0/reg, solver=\"liblinear\", multi_class=\"auto\", random_state=42)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_hat = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy is', acc)"
      ]
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "interpreter": {
      "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('azureml_py36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 2,
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
